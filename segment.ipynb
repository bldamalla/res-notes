{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Notes: Image Segmentation\n",
    "---\n",
    "\n",
    "This should be a continuation of the notes on image histograms.\n",
    "\n",
    "Though notes on the topic may have ended prematurely, it is still advised to read the section first before reading this section as techniques may be referenced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a function for creating dummy image histograms using the `StatsBase` module.\n",
    "\n",
    "We also lift the `intervar(hist::FrequencyWeights, thresh::Int)` function from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interclass variance function\n",
    "function intervar(hist::FrequencyWeights, thresh::Int)\n",
    "  ω_k = fweights(hist[1:thresh]).sum / hist.sum\n",
    "  μ_T = mean(vec(1:length(hist)), hist) / hist.sum\n",
    "  μ_0 = mean(vec(1:thresh), fweights(hist[1:thresh])) / hist.sum\n",
    "  μ_1 = (μ_T-(ω_k*μ_0))/(1-ω_k)\n",
    "    \n",
    "  return (ω_k*(1-ω_k)) * ((μ_0 - μ_1)^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otsu's Method\n",
    "\n",
    "Otsu's method for image segmentation has been used since its discovery in the late 1970s.\n",
    "\n",
    "It splits the image into two groups, background and foreground, based on the frequencies of certain intensities of pixels which can be arranged into __image histograms__.\n",
    "\n",
    "Otsu proposes, that the groups should be split in such a way that the variance _within_ the classes should be _minimized_.\n",
    "Mathematically, since _total variance is constant_, minimizing the __intraclass variance__ means _maximizing_ the __interclass variance__ or variance _between_ classes.\n",
    "\n",
    "Below shows an implementation in Julia of the algorithm referred to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain implementation of Otsu's method\n",
    "function otsu_segment(hist::FrequencyWeights)\n",
    "    # set variance to the lowest reasonable variance\n",
    "    max_var = 0\n",
    "    \n",
    "    # optimal thresh bin\n",
    "    thresh = 0\n",
    "    \n",
    "    # iterate through entire histogram\n",
    "    for curr in 1:length(hist)\n",
    "        curr_var = intervar(hist, curr)\n",
    "        \n",
    "        # if the curr variance > max (recorded) variance\n",
    "        # update max_var\n",
    "        if max_var < curr_var\n",
    "            max_var = curr_var\n",
    "            thresh = curr\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return thresh\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain modification to the above implementation\n",
    "# Assumes that variance is strictly increasing to optimum thresh\n",
    "# and strictly decreases afterwards\n",
    "\n",
    "# breaks at \"maximum\"\n",
    "function otsu_segment_break(hist::FrequencyWeights)\n",
    "    # same local variable defns as above\n",
    "    max_var = 0; thresh = 0\n",
    "    \n",
    "    # iterate over histogram\n",
    "    for curr in 1:length(hist)\n",
    "        curr_var = intervar(hist, curr)\n",
    "        \n",
    "        # if the curr variance > max (recorded) variance\n",
    "        if max_var < curr_var\n",
    "            max_var = curr_var\n",
    "            thresh = curr\n",
    "            \n",
    "        # if the curr_var less than or equal to the recorded maximum\n",
    "        # then break out of loop\n",
    "        else\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return thresh\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otsu-Checkpoints by Alsaeed (2016)\n",
    "\n",
    "This method uses the concept of trisecting a search array and looking for regions of maximum variance.\n",
    "It is assumed that the algorithm was formed from the fact that interclass variance is found to be __concave__ around the optimal threshold.\n",
    "\n",
    "Since the method searches for regions with maximal variance and then __truncates__ the search array, it can be performed __recursively__.\n",
    "\n",
    "Below, we build a _simple_ function for determining the direction of maximal variance.\n",
    "This only uses the fact of __concavity__ around the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple directions to optimal threshold\n",
    "\n",
    "# returns `dir::Int` with respect to `thresh::Int`\n",
    "# if `dir == 1` then optimal thresh is higher\n",
    "# elseif `dir == -1` then dir is lower\n",
    "# otherwise, `thresh` is the optimal threshold\n",
    "function var_dir(hist::FrequencyWeights, thresh::Int)\n",
    "    if intervar(hist, thresh+1) > intervar(hist, thresh)\n",
    "        return 1\n",
    "    elseif intervar(hist, thresh-1) > intervar(hist, thresh)\n",
    "        return -1\n",
    "    else\n",
    "        return 0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the processes for the proposed \"Otsu-checkopoints\" algorithm (AlSaeed et al., 2016) in the next code cell.\n",
    "\n",
    "I consider the algorithm to be a _range-reduction_ algorithm since it reduces the test range into smaller sub-ranges.\n",
    "There are two parts to the said reduction, however:\n",
    "\n",
    "1. First, is \"peak area\" definition\n",
    "2. Even trisection\n",
    "\n",
    "The first part splits the image histogram into four sections, roughly, formed by the division of the peaks and the mean intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposed otsu-checkpoints algorithm\n",
    "\n",
    "function alsaeed_otsu(hist::FrequencyWeights)\n",
    "    # ready the bins\n",
    "    bins = vec(1:length(hist)) ; init_max_c = 0;\n",
    "    \n",
    "    # get the endpoints of the four histogram segments\n",
    "    μ_T = Int(floor(mean(bins, hist)))\n",
    "    μ_0 = Int(floor(mean(bins[1:μ_T], fweights(hist[1:μ_T]))))\n",
    "    μ_1 = Int(floor(mean(bins[μ_T:end], fweights(hist[μ_T:end]))))\n",
    "    \n",
    "    # the constructed regions are [1, μ_0] , [μ_0, μ_T], [μ_T, μ_1], and [μ_1, end]\n",
    "    # determine which of the checkpoint thresholds splits the histogram\n",
    "    # with the greatest interclass variance\n",
    "    \n",
    "    # still assume interclass concavity around the optimal threshold\n",
    "    # for faster results\n",
    "    if intervar(hist, μ_0) > intervar(hist, μ_T)\n",
    "        init_max_c = μ_0\n",
    "    elseif intervar(hist, μ_T) > intervar(hist, μ_1)\n",
    "        init_max_c = μ_T\n",
    "    else\n",
    "        init_max_c = μ_1\n",
    "    end\n",
    "    \n",
    "    # locally define a recursive function for the second type of range reduction used\n",
    "    function alsaeed_reduction(r_hist::FrequencyWeights)\n",
    "        # define measures of position\n",
    "        l = 1; r = length(r_hist); range = r-l\n",
    "        \n",
    "        # if the length of the reduced histogram is 1, return the element\n",
    "        \n",
    "        # define middle checkpoints in range\n",
    "        ch2 = l + range >> 2\n",
    "        ch3 = l + range >> 1\n",
    "        ch4 = r - range >> 2\n",
    "        \n",
    "        # determine which of the three splits the histogram with greatest interclass variance\n",
    "        if intervar(r_hist, ch2) > intervar(r_hist, ch3)\n",
    "            loc_dir = var_dir(r_hist, ch2)\n",
    "            if loc_dir < 0\n",
    "                return alsaeed_reduction(fweights(r_hist[l:ch2]))\n",
    "            elseif loc_dir > 0\n",
    "                return alseed_reduction(fweights(r_hist[ch2:ch3]))\n",
    "        elseif intervar(r_hist, ch3) > intervar(r_hist, ch4)\n",
    "            return # range with ch3\n",
    "        else\n",
    "            return # range with ch4\n",
    "        end\n",
    "        \n",
    "    end # local reduction function end\n",
    "end # function end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Modification to Otsu (Binary search)\n",
    "\n",
    "This method is slightly different to the method of Alseed above.\n",
    "The only difference is that this proposed method will perform a \"binary search\" instead of trisecting the search array.\n",
    "The implementation will be compared against the two algorithm above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.3",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
